# Exploring_an_AI_music_composer

### A MUSIC GENERATOR?

Can music be generated by a computer? 

This was a question that came into my mind recently. From the knowledge and past research I had, this seemed possible. 
My initial thought process was that it was simply a matter of passing in music data, and getting a model to do the prediction by using some form of memorisation(An LSTM model) and classification (to predict the notes to come in the music socre).

### However, one problem i immediatedly identified was how to convert(encode) music data and pass it through a neural network?

After all, in cases of NLP it usually involves one hot encoding, and for Computer Vision related problems, we can siply use numpy/pytorch/vectors(RGB).
So, how can i do somethong similar for audio data?

Upon conuducting some research into this problem, I chanced upon multiple articles that had already tackled this problem. 

Namely, through the use of MIDI data formats. MIDI allows music data to be easily pre-processed and fed into neural networks for such problem.
(Actually, methods involving CV are definitely possible, as we can simply generate a spectorgram of all the music, and tackle this problem as a CV problem. 
However, MIDI seems to give better results. That being said, I belief there are tradeoffs involved, such as the lack of variety with using MIDI format to process music data)

This mini project is a result of just some minor tweaks to the code and guides i dicovered online. 
IT IS NOT MEANT TO BE MY WORK, BUT RATHER AN ECPLORATION INTO THIS FIELD, AND AN EXPERIMENTATION INTO POSSIBLE AREAS OF IMPROVEMENT. 

Largely inspired via:
https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5

AND

https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/
